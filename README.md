<p align="center" style="font-size: 128px;">🪨</p>

<p align="center"><h1 align="center">STONE SCRAPER</h1></p>
<p align="center">
	<em>Extracting Web Intelligence, One Page at a Time!</em>
</p>
<p align="center">Built with the tools and technologies:</p>
<p align="center">
  <img alt="Markdown" src="https://img.shields.io/badge/Markdown-05122A?style=flat&logo=markdown">
  <img alt="Selenium" src="https://img.shields.io/badge/Selenium-05122A?style=flat&logo=selenium">
  <img alt="Python" src="https://img.shields.io/badge/Python-05122A?style=flat&logo=python">
  <img alt="LangChain" src="https://img.shields.io/badge/LangChain-05122A?style=flat&logo=chainlink">
  <img alt="BeautifulSoup" src="https://img.shields.io/badge/BeautifulSoup-05122A?style=flat&logo=soup&logoColor=white">
  <img alt="Ollama" src="https://img.shields.io/badge/Ollama-05122A?style=flat&logo=ollama">
  <img alt="OpenAI" src="https://img.shields.io/badge/OpenAI-05122A?style=flat&logo=openai">
  <img alt="Streamlit" src="https://img.shields.io/badge/Streamlit-05122A?style=flat&logo=streamlit">
  <img alt="VSCode" src="https://img.shields.io/badge/VS%20Code-05122A?style=flat&logo=visualstudiocode">
</p>

<details><summary>Table of Contents</summary>

- [📍 Overview](#-overview)
- [👾 Features](#-features)
- [📁 Project Structure](#-project-structure)
	- [📂 Project Index](#-project-index)
- [🚀 Getting Started](#-getting-started)
	- [☑️ Prerequisites](#️-prerequisites)
	- [⚙️ Installation](#️-installation)
	- [🤖 Usage](#-usage)
	- [🧪 Testing](#-testing)
- [📌 Project Roadmap](#-project-roadmap)
- [🔰 Contributing](#-contributing)
- [🎗 License](#-license)
- [🙌 Acknowledgments](#-acknowledgments)

</details>
<hr>

## 📍 Overview

StoneScraper.git is a ground-breaking AI-powered tool that transforms the way we harvest data from the web. By automating the extraction of structured data from websites, it offers invaluable assistance to data analysts, web researchers, and anyone interested in web data mining. Leveraging state-of-the-art technologies like Streamlit, Langchain, and Selenium, it streamlines web scraping, HTML cleaning, and data parsing. The result? A user-friendly, efficient, and interactive solution that turns unstructured web content into organized, actionable insights.

---

## 👾 Features

|     |      Feature      | Summary                                                                                                                                                                                                                                                                                                                         |
| :-- | :---------------: | :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| ⚙️  | **Architecture**  | <ul><li>The architecture is based on a Python-powered script.</li><li>The project is structured into distinct script files for specific tasks such as `scrape.py` for web scraping and `parse.py` for data parsing.</li><li>The `main.py` script integrates all functions and provides an interactive user interface.</li></ul> |
| 🔩  | **Code Quality**  | <ul><li>The code is well-structured into separate Python scripts with specific tasks.</li><li>There is a clear distinction of tasks among different scripts such as `main.py`, `scrape.py`, and `parse.py`.</li><li>The use of Python and its simplicity ensures maintainability and readability of the code.</li></ul>         |
| 📄  | **Documentation** | <ul><li>The primary language used is Python, with 3 Python files in the project.</li><li>Installation and usage commands are well-documented.</li><li>Dependencies are managed through the `requirements.txt` file.</li></ul>                                                                                                   |
| 🔌  | **Integrations**  | <ul><li>The project integrates several Python packages such as `streamlit`, `langchain`, `selenium`, and `beautifulsoup4`.</li><li>It also includes `chromedriver` for web navigation and scraping.</li><li>The `python-dotenv` package is used for managing environment variables.</li></ul>                                   |
| 🧩  |  **Modularity**   | <ul><li>Tasks are separated into different scripts ensuring high modularity.</li><li>`scrape.py` handles web scraping, `parse.py` handles data parsing, and `main.py` integrates all functionalities.</li><li>The use of `requirements.txt` for managing dependencies also adds to the modularity.</li></ul>                    |
| 🧪  |    **Testing**    | <ul><li>Unit tests can be run using the `pytest` command as indicated in the documentation.</li><li>However, specific details about the test coverage and the results are not provided.</li></ul>                                                                                                                               |
| ⚡️ |  **Performance**  | <ul><li>The use of `selenium` and `chromedriver` ensures efficient web scraping.</li><li>`beautifulsoup4` and `lxml` allow for fast and efficient HTML parsing.</li><li>The `langchain` and `langchain_ollama` packages provide high-performance language processing capabilities.</li></ul>                                    |
| 🛡️  |   **Security**    | <ul><li>The use of `python-dotenv` for managing environment variables provides a level of security for sensitive data.</li><li>However, without more details about authentication or encryption methods, a complete security analysis cannot be provided.</li></ul>                                                             |

---

## 📁 Project Structure

```sh
└── Stone_Scraper.git/
    ├── README.md
    ├── __pycache__
    │   ├── parse.cpython-313.pyc
    │   └── scrape.cpython-313.pyc
    ├── chromedriver
    ├── main.py
    ├── parse.py
    ├── requirements.txt
    └── scrape.py
```

### 📂 Project Index

<details open>
	<summary><b><code>STONE_SCRAPER.GIT/</code></b></summary>
	<details> <!-- __root__ Submodule -->
		<summary><b>__root__</b></summary>
		<blockquote>
			<table>
			<tr>
				<td><b><a href='https://github.com/ralstonraphael/Stone_Scraper.git/blob/master/chromedriver'>chromedriver</a></b></td>
				<td>- Without the complete information provided, such as the project structure and the specific code file, it's quite challenging to give an accurate summary<br>- Could you please provide the missing data? I will then be able to highlight the main purpose and use of the code file in regards to the entire codebase architecture.</td>
			</tr>
			<tr>
				<td><b><a href='https://github.com/ralstonraphael/Stone_Scraper.git/blob/master/main.py'>main.py</a></b></td>
				<td>- Main.py powers the Stone Scraper, a web intelligence tool that extracts structured data from websites using artificial intelligence<br>- It manages the web scraping process, runs AI parsing on the cleaned content, and provides an interactive user interface for data extraction<br>- It's essential for data analysts, web researchers, and individuals interested in data extraction from websites.</td>
			</tr>
			<tr>
				<td><b><a href='https://github.com/ralstonraphael/Stone_Scraper.git/blob/master/scrape.py'>scrape.py</a></b></td>
				<td>- Scrape.py is instrumental in automating web scraping processes, extracting HTML content, and managing secure credentials<br>- It deploys a browser, navigates to specified websites, and retrieves full-page HTML<br>- The script further cleans the HTML by removing scripts/styles and unnecessary whitespace<br>- It also breaks down the DOM text into manageable chunks, facilitating subsequent processing stages.</td>
			</tr>
			<tr>
				<td><b><a href='https://github.com/ralstonraphael/Stone_Scraper.git/blob/master/requirements.txt'>requirements.txt</a></b></td>
				<td>- Requirements.txt manages dependencies for the project, specifying Python packages like Streamlit, Langchain, Selenium, BeautifulSoup4, and others<br>- These packages aid in web scraping, XML parsing, environment management, and building interactive web applications, thus forming a crucial part of the project's functionality.</td>
			</tr>
			<tr>
				<td><b><a href='https://github.com/ralstonraphael/Stone_Scraper.git/blob/master/parse.py'>parse.py</a></b></td>
				<td>- Parse.py utilizes the OllamaLLM language model to extract quantitative or structured data from web content<br>- It generates structured prompts, applies the language model, then parses and combines web content chunks based on these prompts<br>- The outcome is a single string of parsed results, potentially formatted as a clean table.</td>
			</tr>
			</table>
		</blockquote>
	</details>
</details>

---

## 🚀 Getting Started

### ☑️ Prerequisites

Before getting started with Stone_Scraper.git, ensure your runtime environment meets the following requirements:

- **Programming Language:** Python
- **Package Manager:** Pip

### ⚙️ Installation

Install Stone_Scraper.git using one of the following methods:

**Build from source:**

1. Clone the Stone_Scraper.git repository:

```sh
❯ git clone https://github.com/ralstonraphael/Stone_Scraper.git
```

2. Navigate to the project directory:

```sh
❯ cd Stone_Scraper.git
```

3. Install the project dependencies:

**Using `pip`** &nbsp; [<img align="center" src="https://img.shields.io/badge/Pip-3776AB.svg?style={badge_style}&logo=pypi&logoColor=white" />](https://pypi.org/project/pip/)

```sh
❯ pip install -r requirements.txt
```

### 🤖 Usage

Run Stone_Scraper.git using the following command:
**Using `pip`** &nbsp; [<img align="center" src="https://img.shields.io/badge/Pip-3776AB.svg?style={badge_style}&logo=pypi&logoColor=white" />](https://pypi.org/project/pip/)

```sh
❯ python {entrypoint}
```

### 🧪 Testing

Run the test suite using the following command:
**Using `pip`** &nbsp; [<img align="center" src="https://img.shields.io/badge/Pip-3776AB.svg?style={badge_style}&logo=pypi&logoColor=white" />](https://pypi.org/project/pip/)

```sh
❯ pytest
```

---

## 📌 Project Roadmap

- [x] **`Task 1`**: <strike>Implement webscraper API.</strike>
- [ ] **`Task 2`**: Implement OpenAI API and deploy though cloud.
- [ ] **`Task 3`**: Additional option to input your own API key.

---

## 🔰 Contributing

- **💬 [Join the Discussions](https://github.com/ralstonraphael/Stone_Scraper.git/discussions)**: Share your insights, provide feedback, or ask questions.
- **🐛 [Report Issues](https://github.com/ralstonraphael/Stone_Scraper.git/issues)**: Submit bugs found or log feature requests for the `Stone_Scraper.git` project.
- **💡 [Submit Pull Requests](https://github.com/ralstonraphael/Stone_Scraper.git/blob/main/CONTRIBUTING.md)**: Review open PRs, and submit your own PRs.

<details closed>
<summary>Contributing Guidelines</summary>

1. **Fork the Repository**: Start by forking the project repository to your github account.
2. **Clone Locally**: Clone the forked repository to your local machine using a git client.
   ```sh
   git clone https://github.com/ralstonraphael/Stone_Scraper.git
   ```
3. **Create a New Branch**: Always work on a new branch, giving it a descriptive name.
   ```sh
   git checkout -b new-feature-x
   ```
4. **Make Your Changes**: Develop and test your changes locally.
5. **Commit Your Changes**: Commit with a clear message describing your updates.
   ```sh
   git commit -m 'Implemented new feature x.'
   ```
6. **Push to github**: Push the changes to your forked repository.
   ```sh
   git push origin new-feature-x
   ```
7. **Submit a Pull Request**: Create a PR against the original project repository. Clearly describe the changes and their motivations.
8. **Review**: Once your PR is reviewed and approved, it will be merged into the main branch. Congratulations on your contribution!
</details>

<details closed>
<summary>Contributor Graph</summary>
<br>
<p align="left">
   <a href="https://github.com{/ralstonraphael/Stone_Scraper.git/}graphs/contributors">
      <img src="https://contrib.rocks/image?repo=ralstonraphael/Stone_Scraper.git">
   </a>
</p>
</details>

---

## 🎗 License

This project is protected under the [Unlicence](https://choosealicense.com/licenses). For more details, refer to the [LICENSE](https://Unlicence.com/licenses/) file.

---

## 🙌 Acknowledgments

I’d like to express my gratitude to the tools, libraries, and communities that made this project possible:

- **[Streamlit](https://streamlit.io/)** – for making it incredibly easy to build interactive web apps with Python.
- **[LangChain](https://www.langchain.com/)** – for providing a powerful framework to integrate LLMs in structured pipelines.
- **[OpenAI](https://openai.com/)** – for their accessible and reliable language models, powering intelligent text analysis.
- **[Ollama](https://ollama.com/)** – for enabling local LLM experimentation and model integration.
- **[Selenium](https://www.selenium.dev/)** – for automating browser interactions and web scraping workflows.
- **[BeautifulSoup](https://www.crummy.com/software/BeautifulSoup/)** – for efficient and intuitive HTML parsing.
- **[Python](https://www.python.org/)** – the language at the core of everything.
- Special thanks to the open-source community for making powerful tools accessible to everyone.

---
